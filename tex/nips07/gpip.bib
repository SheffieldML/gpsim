@string{icml =     {Proceedings of the International Conference in 
                   Machine Learning}}
@string{springer = {Springer-Verlag}}
@InProceedings{Murray-Smith:transformations05,
  author = 	 {Roderick Murray-Smith and Barak A. Pearlmutter},
  title = 	 {Transformations of {G}aussian Process priors},
  crossref =	 {Winkler:smlw04},
  pages =	 {110--123},
  linkpdf =	 {http://www.dcs.gla.ac.uk/~rod/publications/MurPea05.pdf},
  year = 2005,
  OPTabstract =  {},
  OPTgroup = 	 {}
}
@Book{Winkler:smlw04,
  editor =	 {Joab Winkler and Neil D. Lawrence and Mahesan Niranjan},
  booktitle = 	 {Deterministic and Statistical Methods in Machine Learning},
  title = 	 {Deterministic and Statistical Methods in Machine Learning},
  publisher = 	 springer,
  year = 	 2005,
  volume =	 3635,
  series =	 {Lecture Notes in Artificial Intelligence},
  address = 	 {Berlin},
  ISBN = 	 {3-540-29073-7},
  label1 =  	 {Springer Site},
  link1 =  	 {http://www.springeronline.com/3-540-29073-7},
  group =  	 {shefml}
}
@InProceedings{Graepel:gpdiff03,
  author = 	 {Thore Graepel},
  title = 	 {Solving Noisy Linear Operator Equations by {G}aussian 
                 Processes: Application to Ordinary and Partial Differential 
                 Equations},
  crossref =	 {Fawcett:icml03},
  pages =	 {234--241},
  linkpdf =	 {http://www.research.microsoft.com/~thoreg/papers/graepel03.pdf},
  abstract =	 {We formulate the problem of solving stochastic linear 
                 operator equations in a Bayesian Gaussian process
                 (GP) framework. The solution is obtained in the
                 spirit of a collocation method based on noisy
                 evaluations of the target function at randomly drawn
                 or deliberately chosen points. Prior knowledge about
                 the solution is encoded in terms of the covariance
                 kernel of the GP. As in GP regression, analytical
                 expressions for the mean and variance of the
                 estimated target function are obtained from which the
                 solution to the operator equation follows by a
                 manipulation of the kernel. Linear initial and
                 boundary value constraints can be enforced by
                 embedding the non-parametric model in a form that
                 automatically satisfies the boundary conditions. The
                 method is illustrated on a noisy linear first-order
                 ordinary differential equation with initial condition
                 and on a noisy second-order partial differential
                 equation with Dirichlet boundary conditions.},
  group =	 {gp, ode}
}

@Proceedings{Fawcett:icml03,
  title = 	 icml,
  year = 	 2003,
  editor =	 {Tom Fawcett and Nina Mishra},
  booktitle =    icml,
  volume =	 20,
  ISBN = 	 {1-57735-189-4},
  publisher =	 {AAAI Press}
}

@Article{Sabatti06,
  author =	 {Chiara Sabatti and Gareth M. James},
  title =	 {Bayesian Sparse Hidden Components Analysis for Transcription
                  Regulation Networks},
  journal =	 {Bioinformatics},
  volume =	 22,
  number =	 6,
  year =	 2006,
  pages =	 {739--746}
}
@Article{Sanguinetti:chipdyno06,
  author = 	 {Guido Sanguinetti and Magnus Rattray and Neil D. Lawrence},
  title = 	 {A probabilistic dynamical model for quantitative inference of the regulatory mechanism of transcription},
  journal = 	 {Bioinformatics},
  year = 	 2006,
  volume =	 22,
  number =	 14,
  pages =	 {1753--1759},
  label1 =	 {Advance Access},
  link1 =	 {http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btl154v1},
  label2 =	 {Supplementary Material},
  link2 = 	 softwarehttp # {chipdyno/supplementary.pdf},
  linksoftware = 	 softwarehttp # {chipdyno/},
  OPTlinkpdf =	 {},
  abstract =	 {{\bf Motivation:} Quantitative estimation of the regulatory 
                 relationship between transcription factors and genes
                 is a fundamental stepping stone when trying to
                 develop models of cellular processes. This task,
                 however, is difficult for a number of reasons:
                 transcription factors' expression levels are often
                 low and noisy, and many transcription factors are
                 post-transcriptionally regulated. It is therefore
                 useful to infer the activity of the transcription
                 factors from the expression levels of their target
                 genes.\\\\

                 {\bf Results:} We introduce a novel probabilistic
                 model to infer transcription factor activities from
                 microarray data when the structure of the regulatory
                 network is known. The model is based on regression,
                 retaining the computational efficiency to allow
                 genome-wide investigation, but is rendered more
                 flexible by sampling regression coefficients
                 independently for each gene. This allows us to
                 determine the strength with which a transcription
                 factor regulates each of its target genes, therefore
                 providing a quantitative description of the
                 transcriptional regulatory network. The probabilistic
                 nature of the model also means that we can associate
                 credibility intervals to our estimates of the
                 activities. We demonstrate our model on two yeast
                 data sets. In both cases the network structure was
                 obtained using Chromatine Immunoprecipitation
                 data. We show how predictions from our model are
                 consistent with the underlying biology and offer
                 novel quantitative insights into the regulatory
                 structure of the yeast cell.\\\\

                 {\bf Availability:} MATLAB code is available from
                 \url{http://umber.sbs.man.ac.uk/resources/puma}.},
  group =	 {gene networks,shefml,puma}
}

@Article{Barenco:ranked06,
  author = 	 {Martino Barenco and Daniela Tomescu and Daniel Brewer and Robin Callard and Jaroslav Stark and Michael Hubank},
  title = 	 {Ranked prediction of p53 targets using hidden variable dynamic modeling},
  journal = 	 {Genome Biology},
  year = 	 2006,
  volume =	 7,
  number =	 3,
  pages =	 {R25},
  linkpdf = 	 {http://genomebiology.com/content/pdf/gb-2006-7-3-r25.pdf},
  linkhtml = 	 {http://genomebiology.com/2006/7/3/R25},
  abstract =	 {Full exploitation of microarray data requires hidden 
                 information that cannot be extracted using current
                 analysis methodologies. We present a new approach,
                 hidden variable dynamic modeling (HVDM), which
                 derives the hidden profile of a transcription factor
                 from time series microarray data, and generates a
                 ranked list of predicted targets. We applied HVDM to
                 the p53 network, validating predictions
                 experimentally using small interfering RNA. HVDM can
                 be applied in many systems biology contexts to
                 predict regulation of gene activity quantitatively.},
  group =	 {gene networks, single input motifs}
}
@InProceedings{Chen:modelling99,
  author = 	 {T. Chen and H.L.He and G.M. Church},
  title = 	 {Modeling gene expression with differential equations},
  booktitle = 	 {Pacific Symposium in Biocomputing},
  year = 	 1999,
  volume =	 {},
  number =	 {},
  pages =	 {29--40},
  
  group =	 {gene networks}
}
@Book{Neal:book96,
  author =	 {Radford M. Neal},
  title =	 {{B}ayesian Learning for Neural Networks},
  publisher =	 {Springer},
  note =	 {Lecture Notes in Statistics 118},
  year =	 {1996}
}
@Article{Williams:computation98,
  author = 	 {Christopher K. I. Williams},
  title = 	 {Computation with Infinite Neural Networks},
  journal = 	 {Neural Computation},
  year = 	 1998,
  volume =	 10,
  number =	 5,
  pages =	 {1203--1216},
  label1 = 	 {Zipped PS},
  link1 = 	 {http://www.ncrg.aston.ac.uk/Papers/postscript/NCRG_97_025.ps.zip},
  abstract = 	 {For neural networks with a wide class of weight priors, it 
                 can be shown that in the limit of an infinite number
                 of hidden units the prior over functions tends to a
                 Gaussian process. In this paper analytic forms are
                 derived for the covariance function of the Gaussian
                 processes corresponding to networks with sigmoidal
                 and Gaussian hidden units. This allows predictions to
                 be made efficiently using networks with an infinite
                 number of hidden units, and shows that, somewhat
                 paradoxically, it may be easier to carry out Bayesian
                 prediction with infinite networks rather than finite
                 ones. }

}
@Article{Monk03,
  author =	 {Nicholas A.M. Monk},
  title =	 {Unravelling Nature's Networks},
  journal =	 {Biochemical Society Transactions},
  volume =	 31,
  number =	 {},
  year =	 2003,
  pages =	 {1457--1461}
}
@Article{Liao:nca03,
  author =	 {James C. Liao and Riccardo Boscolo and Young-Lyeol Yang 
                  and Linh My Tran and Chiara Sabatti and 
                  Vwani P. Roychowdhury},
  title =	 {Network Component Analysis: Reconstruction of Regulatory 
                  Signals in Biological Systems},
  journal =	 {Proceedings of the National Academy of Sciences USA},
  volume =	 100,
  number =	 26,
  year =	 2003,
  group =	 {gene networks},
  pages =	 {15522--15527}
}

@Article{Boulesteix:predicting05,
  author =	 {Anne-Laure Boulesteix and Korbinian Strimmer},
  title =	 {Predicting Transcription Factor Activities from Combined 
                  Analysis of Microarray and {ChIP} Data: a Partial Least 
                  Squares Approach},
  journal =	 {Theor. Biol. Med. Model.},
  volume =	 2,
  number =	 23,
  group =	 {gene networks},
  year =	 2005,
  pages =	 {1471--16582}
}
@InProceedings{Rogers:model06b,
  author = 	 {Simon Rogers and Raya Khanin and Mark Girolami},
  title = 	 {Model Based Identification of Transcription Factor Activity from Microarray Data},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =	 {Probabilistic Modeling and Machine Learning in Structural and Systems Biology},
  linkpdf =	 {http://www.cs.helsinki.fi/group/bioinfo/events/pmsb06/final/rogers_et_al.pdf},
  year =	 2006,
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  address =	 {Tuusula, Finland},
  month =	 {17-18th June},
  OPTorganization = {},
  OPTpublisher = {},
  OPTnote = 	 {},
  group =	 {gene networks}
}
@Book{Rasmussen:book05,
  author =       {Carl E. Rasmussen and Christopher K.I. Williams},
  title  =       {{G}aussian Processes for Machine Learning},
  publisher =    {MIT press},
  year  =        {2005}
}
@Article{Schlitt05,
  author =	 {Thomas Schlitt and Alvis Brazma},
  title =	 {Modelling gene networks at different organisational levels},
  journal =	 {FEBS letts},
  volume =	 579,
  number =	 8,
  year =	 2005,
  pages =	 {1859--1866}
}
@Article{Liu:mmgmos05,
  author = 	 {Xuejun Liu and Marta Milo and  Neil D. Lawrence and Magnus Rattray},
  title = 	 {A Tractable Probabilistic Model for Affymetrix Probe-level Analysis Across Multiple Chips},
  journal = 	 {Bioinformatics},
  year = 	 2005,
  volume =       21,
  number =       18,
  pages =        {3637--3644}
}
