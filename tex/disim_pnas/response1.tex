\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{soul}

\setlength{\parindent}{0pt}
\setlength{\parskip}{3mm}

\newcommand{\myquote}[1]{\begin{quote}#1\end{quote}}

\begin{document}

\begin{center}
\textbf{\LARGE Summary of changes and response to reviewer comments}
\end{center}

We wish to thank all the reviewers for their constructive comments
that have helped us improve the paper.

\section*{Reviewer 1}

%\begin{itemize}
%\item
  \begin{quote}
    The discussion is clear and well presented. I think that the
    description of Gaussian Processes is easy to follow, and even
    non-specialists will be able to get the gist of the
    methodology. The discussion of why to use only a linear model
    needs perhaps some expansion; clearly there are two rationales:

1. this makes the GP procedure vastly more convenient 

2. By itself this may not be such a bad approximation to non-linear models 

The latter can be shown or rationalized using eg perturbation
approaches. The former is perhaps more important as it allows scanning
of vast datasets in very short time. In the present description both
points may need some expansion.
  \end{quote}

Clarified this in the beginning of Discussion:
\emph{The linear differential equation model of regulation we use
is a simplification, and in many cases unrealistic, but it can capture important differences in
the profiles of target genes due to differences in protein and mRNA
stability while still keeping the computational load at a level
that allows us to perform genome-wide scoring using reasonably modest
computational resources \ul{without the need for expensive sampling.
When data are limited then the linear model can provide a sufficiently good
approximation to a non-linear model. The linear model does not restrict concentrations from being negative
and occasionally the inferred credible region of functions extends to negative
values. However, as the parameters and observations are constrained to be positive,
this is rare and does not seem to affect the ranking performance.}}

%\item
\begin{quote} In the context of the log-likelihood the first
    term may be written/expressed in terms of the Mahalanobis
    distance. And while the manuscript is generally well written, the
    discussion of the ranking requires some classification.
  \end{quote}

The following paragraph clarifying the ranking method was added
under section ``Gaussian process inference for a linear activation
model'' (end of page 2):
\emph{We use the likelihood to rank genes according to their fit to the
regulation model. Genes with a
near-constant profile may have high likelihoods without being targets,
but we find that filtering of weakly expressed genes removes most of
these (see Materials and Methods). It is also possible to filter
targets using a comparison to a model with
zero sensitivity but we find that the proposed approach achieves
similar results with significantly smaller computational cost.}

%\item
\begin{quote} I would also like to see some clarification
    regarding the bootstrapping procedure: was the time-course
    bootstrapped? This would clearly destroy much of the information;
    gaussian process regression would be a better method to generate
    bootstrap samples (see Kirk et al Bioinformatics
    2009). Unfortunately, the supplementary material (which,
    incidentally, has everything twice), in particular table S1 is not
    very illuminating. In the supplementary material the derivation of
    the gaussian process is correct but could do with a few more words
  \end{quote}

To avoid extensive computation from having to re-fit the models to
resampled data, bootstrapping was implemented by resampling the set
of observed genes.  The caption of Table S1 has been clarified
to begin with:
\emph{The results of 100,000-fold bootstrap resampling of
the data set of observed genes}

The derivation of the Gaussian process model in supplementary material
has been expanded.

%\item
\begin{quote} A minor concern are the figures; especially
    figures 1,2 and 3,4 could perhaps be combined.
  \end{quote}

  Figures 3,4 have been combined. Combining figures 1,2 would be
  extremely difficult due to incompatible geometries.

%\item
  \begin{quote} Finallly, in the results section and discussion
    the authors provide details as to why single target data may
    provide a better fit compared to five targets. I agree entirely
    with this discussion but was left wondering if there is some $n$
    for which the method would no longer reliably identify sets of
    targets (always assuming that $n$ is less than the number of true
    targets). But this is probably a minor point as the method
    developed in the paper is clearly targeted at a different problem.
  \end{quote}

  Assuming the $n$ refers to the number of training targets to
  consider, it seems unlikely there would be any benefit from going
  beyond 5.  With e.g. 10 targets, the model has a tendency to overfit
  the GP as the linear model is too inflexible to capture all the
  different target behaviours simultaneously.

  %MAGNUS: SHOULD WE ADD SOMETHING TO THE PAPER? - No need I think.

%\end{itemize}

\newpage

\section*{Reviewer 2}

%\begin{itemize}
%\item
\begin{quote} The authors describe an approach to the analysis
    of gene-expression time-series data that avoids discretization and
    over-fitting by applying the gaussian process approach to
    integrate out the functional parameters allowing fitting of the
    dynamic parameters and ranking of candidate targets. To someone a
    little out of this area, it seems an elegant approach worthy of
    wider dissemination. My primary hesitation, again as someone not
    directly in this field, concerns the novelty of this work given
    the previous articles by some of these authors [Bioinformatics
    (ref. 8) and Lawrence (2007) therein]. This could be more clearly
    spelled out in the introduction. Overall, the paper is
    well-written and informative for a wider audience.
\end{quote}

The main novel aspects in this work are (1) the the use of the model likelihood
for target-ranking and (2) the development of a single-target model which
does not require a training set. This single-target model performs
best in our evaluation so is actually the most significant
contribution of the paper. In addition to these important new
developments the training set model developed here was described only
very briefly in the final section of ref. [8] with no
mathematical detail and no evaluation. The present paper is the first to
provide a very thorough empirical evaluation of the performance of the
GP approach and coincides with the release of new software for
target ranking that we developed here. 

%\item
\begin{quote} Are the concentrations allowed to become negative?
    This is discussed in the previous articles but not mentioned here,
    so it looks as if this is not considered to be an issue. It seems
    as if this could come up in some of the single-target models,
    particularly if they were being directly or indirectly
    repressed...
\end{quote}

In our experience negative concentrations seem rare in practice
because the positive parameters and TF mRNA observations strongly
favour positive values.  Especially the TF mRNA observations help in
making that issue far less significant than in our previous papers.

The following explanation has been added to the beginning of Discussion:
\emph{The linear model does not restrict concentrations from being negative
and occasionally the inferred credible region of functions extends to negative
values. However, as the parameters and observations are constrained to be positive,
this is rare and does not seem to affect the ranking performance.}

%\item
\begin{quote} From the Results text it sounds like the targets
    are ranked by their model likelihood, but the beginning of the
    Discussion describes ranking genes "according their likelihood of
    being targeted by a specific TF." In the former, the actual
    magnitude of the sensitivity parameter Sj wouldn't matter - a
    non-responsive gene could be well-fit by a model that has Sj=0 -
    whereas the use of targeted in the latter description suggests
    that Sj perhaps does matter. If the former, why is it not
    necessary to look also at the degree of sensitivity to the TF when
    ranking genes? Perhaps this is handled by the filtering for weakly
    expressed genes, but it seems as if the issue could come up with
    other genes as well.
\end{quote}

This is a very good point that was not sufficiently addressed in the
original submission.  The targets are indeed ranked by their model
likelihood, which according to the results correlates with the
likelihood of being targeted by a specific TF within the set of
genes passing the filtering for weak expression.

As an alternative, it would be possible to consider comparison to a
model with $S_j = 0$, but we did not include that here because the
filtering produced similar results with smaller computational cost as
it avoid fitting any models for the uninformative genes.  The model
comparison approach is certainly important in case the proposed
filtering is not possible (e.g.\ with data from a different platform
with less sophisticated pre-processing tools).

The following paragraph clarifying the ranking method was added
under section ``Gaussian process inference for a linear activation
model'' (end of page 2):
\emph{We use the likelihood to rank genes according to their fit to the
regulation model. Genes with a
near-constant profile may have high likelihoods without being targets,
but we find that filtering of weakly expressed genes removes most of
these (see Materials and Methods). It is also possible to filter
targets using a comparison to a model with
zero sensitivity but we find that the proposed approach achieves
similar results with significantly smaller computational cost.}

%\end{itemize}

\newpage

\section*{Reviewer 3}

%\begin{itemize}
%\item
\begin{quote}
Point 1 - Presentation 

I think I got the gist of how the method works - you model the protein
levels for a TF as a family of time-series, and compute the likelihood
of a given gene being a target by considering the whole family. Is
there any way to illustrate this idea? Most readers will not be able
to get a good sense of the model from the text and equations. It took
me a while, and I'm used to reading this kind of thing. The
presentation of inferred protein levels in Figs 1 and 2 confounds this
confusion, as it makes it seem like you are selecting a single protein
profile at the end of the day rather than a distribution over
profiles. Am I misunderstanding this?
\end{quote}

Figs 1 and 2 actually show a distribution over the inferred protein
profiles, not just single profiles.

The caption of Fig.~1 has been clarified to better stress this:
\emph{The inferred posterior means of the functions are shown in blue
  and the shaded regions denote 2 s.d.\ posterior confidence
  intervals.}

%\item 
\begin{quote}
Point 2 - Marginal value of gaussian process model 

There are clearly differences between the success of your model and of
a model based on correlation. But there are several differences
between the model you present and correlation - most notably the use
of differential equations to relate observed expression of the target
and inferred expression of the TF. Isn't it possible that the
advantages of the model accrue solely from this feature and not the
GP? It should be easy to evaluate this.
\end{quote}

We have performed an additional comparison against direct maximum
likelihood fit using a quadrature-based solution of the same
differential equation model which demonstrates the advantage given
by the GP approach.  Note that this simplification of our method is
also novel.  The results have been included in the text:
\emph{To evaluate the advantage from using Gaussian processes in our
approach, we performed a comparison to direct maximum likelihood fit
of the same differential equation model using the observed TF mRNA
levels $\hat{f}_i(t_j)$ in trapezoidal quadrature evaluation of
Eqs.~[3--4]
(``single-target quadrature'').}

\emph{Overall, the Gaussian process methods tend to perform better than the
quadrature-based method. The differences are statistically significant
in focused Twist validation for top 250 list and several Mef2 validation
settings for top 100 and top 250 lists.}

%\item
\begin{quote} I'm also curious if the model is indirectly
    selecting for features that might themselves be associated with
    being targets of the TF in question. For example, I would imagine
    the GP models are less sensitive to noise than the correlation
    score is - or that they select genes with different overall levels
    of expression than the correlation metric. Is this true. And, if
    so, does this account for the difference between the models?
\end{quote}

This is a very interesting question, but to which it is very difficult
to give a complete answer.

All methods use data with gene-wise normalised expression levels and
there is nothing that would explicitly favour genes with certain
overall level of expression.  That said, genes with low overall
expression tend to be more noisy, and that is captured by the noise
estimates we have from pre-processing, which are then handled somewhat
differently by different methods.

Anecdotally in the case of Mef2 (Fig.~2), the GP model seems to smooth
the data quite strongly and therefore misses faster responding genes
that correlation picks up.

%MAGNUS: SHOULD WE ADD SOMETHING TO THE PAPER? - No, too speculative.

%\item 
\begin{quote} All in all this is my major concern about the
    paper - and it's one that runs throughout the field - the authors
    convince me that the method is interesting and has potential, but
    they don't directly ask whether the features of the model they are
    highlighting really account for its success.
\end{quote}

We hope the new comparison to direct maximum-likelihood-type approach
with the same ODE model that demonstrates the superiority of the GP
approach addresses this concern.

%\end{itemize}

\end{document}
